{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass object identifcation of dog breeds, Keras Edition\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os.path\n",
    "\n",
    "import keras\n",
    "from keras import applications, metrics, layers, models, regularizers, optimizers\n",
    "from keras.applications import ResNet50, Xception, InceptionResNetV2\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Globals\n",
    "BATCH_SIZE = 32   # tweak to your GPUs capacity\n",
    "IMG_HEIGHT = 299   # ResNetInceptionv2 & Xception like 299, ResNet50 & VGG like 224\n",
    "IMG_WIDTH = IMG_HEIGHT\n",
    "CHANNELS = 3\n",
    "DIMS = (IMG_HEIGHT,IMG_WIDTH,CHANNELS) # what an ugly holdover from a framework not even supported by it's authors\n",
    "BEST_MODEL = 'keras.best.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data : loaders, standardization, and augmentation\n",
    "\n",
    "\n",
    "\n",
    "Assumes following directory structure.\n",
    "\n",
    "```bash\n",
    ".\n",
    "├── data\n",
    "│   ├── classify_by_dir.sh\n",
    "│   ├── labels.csv\n",
    "│   ├── sample_submission.csv\n",
    "│   ├── sample_submission.csv.zip\n",
    "│   ├── test\n",
    "│   ├── test.zip\n",
    "│   ├── train\n",
    "│   ├── train.zip\n",
    "│   ├── unsorted\n",
    "│   └── val\n",
    "├── keras.best.h5\n",
    "├── keras.ipynb\n",
    "└── submit.csv\n",
    "```\n",
    "Save the following script in your data directory as `classify_by_dir.sh` then run\n",
    "\n",
    "`unzip train.zip && mv train unsorted && ./classify_by_dir.sh`\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "shuf -o labels.csv <labels.csv\n",
    "unsorted_dir=unsorted\n",
    "counter=0\n",
    "# SHUFFLE THE FILE WOOO\n",
    "while IFS=, read -r image class; do\n",
    "\t# very roughly 25% to val\n",
    "\tif (($counter == 4)); then\n",
    "\t\tsorted_dir=val\n",
    "\t\tmkdir -p $sorted_dir/$class\n",
    "\t\tmv $unsorted_dir/$image.jpg $sorted_dir/$class/$image.jpg\n",
    "\t\tcounter=0\n",
    "\telse\n",
    "\t\tsorted_dir=train\n",
    "\t\tmkdir -p $sorted_dir/$class\n",
    "\t\tmv $unsorted_dir/$image.jpg $sorted_dir/$class/$image.jpg\n",
    "\tfi\n",
    "\t((counter++))\n",
    "\n",
    "done <labels.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7667 images belonging to 120 classes.\n",
      "Found 2555 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    shear_range=0.1,)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'data/train',  # this is the target directory\n",
    "    target_size=(IMG_HEIGHT,IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical')\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    'data/val',\n",
    "    target_size=(IMG_HEIGHT,IMG_WIDTH), \n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = len(train_generator.class_indices)\n",
    "assert classes > 0\n",
    "# sometimes \"breed\" gets thrown in there because i forgot to tr the first line of the csv\n",
    "assert classes is len(val_generator.class_indices)\n",
    "n_of_train_samples = train_generator.samples\n",
    "n_of_val_samples = val_generator.samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "There are [many CNN architectures](https://towardsdatascience.com/neural-network-architectures-156e5bad51ba) to pick from with trade-offs in both size, ops, and accuracy. ResNet50 is my \"safe choice\". I went with Xception for this particular project because it's kinda a Keras specific thing because Chollet is both the author of Keras and Xception. \n",
    "\n",
    "![https://cdn-images-1.medium.com/max/1600/1*kBpEOy4fzLiFxRLjpxAX6A.png](https://cdn-images-1.medium.com/max/1600/1*kBpEOy4fzLiFxRLjpxAX6A.png)\n",
    "\n",
    "### Fine-tune\n",
    "\n",
    "Pay particular attention to the new prediction layers here as they differ greatly by architecture. I saw a lot of busted code where people were using prediction fully connected layers that were not at all related to the architecture they were using. Many are using sigmoid activations for multiclass problems which is... weird. Don't be afraid of the pretrained models code. It will tell you exactly what the prediction layers should look like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callbacks = [ModelCheckpoint(filepath=BEST_MODEL, verbose=0, save_best_only=True),\n",
    "             EarlyStopping(monitor='val_acc', patience=3, verbose=0)]\n",
    "\n",
    "# base_model = Xception(input_shape=DIMS, weights='imagenet', include_top=False) #~\n",
    "# base_model = ResNet50(input_shape=DIMS, weights='imagenet', include_top=False)\n",
    "base_model = InceptionResNetV2(input_shape=DIMS, weights='imagenet', include_top=False)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "\n",
    "# RESNET50 TOP : https://github.com/keras-team/keras/blob/master/keras/applications/resnet50.py#L237-L239\n",
    "# x = Flatten()(x)\n",
    "# x = Dense(classes, activation='softmax', name='predictions')(x)\n",
    "\n",
    "# XCEPTION TOP : https://github.com/keras-team/keras/blob/master/keras/applications/xception.py#L232-L234\n",
    "# Inception Resnet V2 : https://github.com/keras-team/keras/blob/master/keras/applications/inception_resnet_v2.py#L332-L335\n",
    "x = GlobalAveragePooling2D(name='avg_pool')(base_model.output)\n",
    "x = Dense(classes, activation='softmax', name='predictions')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=optimizers.Adam(1e-3),\n",
    "    metrics=['acc'])\n",
    "\n",
    "model_out = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=n_of_train_samples//BATCH_SIZE,\n",
    "    epochs=15,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=n_of_val_samples//BATCH_SIZE,\n",
    "    verbose=0,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(BEST_MODEL)\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(lr=1e-4,),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['acc'])\n",
    "\n",
    "model_out = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=n_of_train_samples//BATCH_SIZE,\n",
    "    epochs=60,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=n_of_val_samples//BATCH_SIZE,\n",
    "    verbose=0,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain final convolution layer\n",
    "\n",
    "In addition to retraining the prediction layers, I wanted to see if I could retrain the final convolution block to see if I could get an improvement. This differs for every architecture so you'll need to check out the layers of whatever network you are using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(BEST_MODEL)\n",
    "# print(model.summary())\n",
    "# for i, layer in enumerate(model.layers):\n",
    "#     print(i, layer.name)\n",
    "# See model information for last convolution layer. Xception is 126.\n",
    "for layer in model.layers[:126]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[126:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(lr=1e-4,),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['acc'])\n",
    "\n",
    "model_out = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=n_of_train_samples//BATCH_SIZE,\n",
    "    epochs=60,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=n_of_val_samples//BATCH_SIZE,\n",
    "    verbose=0,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Predict\n",
    "\n",
    "Thank you Huy Nguyen for writing this [code](https://www.kaggle.com/baohuy/data-augmentation-pre-trained-xception-0-4) so I didn't have to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clear gpu memory\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "def load_test_image(fpath):\n",
    "    img = image.load_img(fpath, target_size=(IMG_WIDTH, IMG_HEIGHT))\n",
    "    x = image.img_to_array(img)\n",
    "    return x\n",
    "\n",
    "test_labels = np.loadtxt('data/sample_submission.csv', delimiter=',', dtype=str, skiprows=1)\n",
    "test_images = []\n",
    "test_names = test_labels[:,0]\n",
    "for test_name in test_names:\n",
    "   fname = '{}.jpg'.format(test_name)\n",
    "   data = load_test_image(os.path.join('data/test/', fname))\n",
    "   test_images.append(data)\n",
    "\n",
    "test_images = np.asarray(test_images)\n",
    "test_images = test_images.astype('float32')\n",
    "test_images /= 255\n",
    "print(test_images.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "class_indices = sorted([ [k,v] for k, v in train_generator.class_indices.items() ], key=lambda c : c[1])\n",
    "columns = [b[0] for b in class_indices]\n",
    "df = pd.DataFrame(predictions,columns=columns)\n",
    "df = df.assign(id = test_names)\n",
    "df.to_csv(\"submit.csv\", index=False,float_format='%.4f')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
